{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will follow the machine learning life cycle and implement a model to solve a machine learning problem of your choosing. You will select a data set and choose a predictive problem that the data set supports.  You will then inspect the data with your problem in mind and begin to formulate a  project plan. You will then implement the machine learning project plan. \n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build Your DataFrame\n",
    "2. Define Your ML Problem\n",
    "3. Perform exploratory data analysis to understand your data.\n",
    "4. Define Your Project Plan\n",
    "5. Implement Your Project Plan:\n",
    "    * Prepare your data for your model.\n",
    "    * Fit your model to the training data and evaluate your model.\n",
    "    * Improve your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                name  \\\n",
      "0                              Skylit Midtown Castle   \n",
      "1  Whole flr w/private bdrm, bath & kitchen(pls r...   \n",
      "2           Spacious Brooklyn Duplex, Patio + Garden   \n",
      "3                   Large Furnished Room Near B'way　   \n",
      "4                 Cozy Clean Guest Room - Family Apt   \n",
      "\n",
      "                                         description  \\\n",
      "0  Beautiful, spacious skylit studio in the heart...   \n",
      "1  Enjoy 500 s.f. top floor in 1899 brownstone, w...   \n",
      "2  We welcome you to stay in our lovely 2 br dupl...   \n",
      "3  Please don’t expect the luxury here just a bas...   \n",
      "4  Our best guests are seeking a safe, clean, spa...   \n",
      "\n",
      "                               neighborhood_overview    host_name  \\\n",
      "0  Centrally located in the heart of Manhattan ju...     Jennifer   \n",
      "1  Just the right mix of urban center and local n...  LisaRoxanne   \n",
      "2                                                NaN      Rebecca   \n",
      "3    Theater district, many restaurants around here.     Shunichi   \n",
      "4  Our neighborhood is full of restaurants and ca...    MaryEllen   \n",
      "\n",
      "                       host_location  \\\n",
      "0  New York, New York, United States   \n",
      "1  New York, New York, United States   \n",
      "2  Brooklyn, New York, United States   \n",
      "3  New York, New York, United States   \n",
      "4  New York, New York, United States   \n",
      "\n",
      "                                          host_about  host_response_rate  \\\n",
      "0  A New Yorker since 2000! My passion is creatin...                0.80   \n",
      "1  Laid-back Native New Yorker (formerly bi-coast...                0.09   \n",
      "2  Rebecca is an artist/designer, and Henoch is i...                1.00   \n",
      "3  I used to work for a financial industry but no...                1.00   \n",
      "4  Welcome to family life with my oldest two away...                 NaN   \n",
      "\n",
      "   host_acceptance_rate  host_is_superhost  host_listings_count  ...  \\\n",
      "0                  0.17               True                  8.0  ...   \n",
      "1                  0.69               True                  1.0  ...   \n",
      "2                  0.25               True                  1.0  ...   \n",
      "3                  1.00               True                  1.0  ...   \n",
      "4                   NaN               True                  1.0  ...   \n",
      "\n",
      "   review_scores_communication  review_scores_location  review_scores_value  \\\n",
      "0                         4.79                    4.86                 4.41   \n",
      "1                         4.80                    4.71                 4.64   \n",
      "2                         5.00                    4.50                 5.00   \n",
      "3                         4.42                    4.87                 4.36   \n",
      "4                         4.95                    4.94                 4.92   \n",
      "\n",
      "  instant_bookable calculated_host_listings_count  \\\n",
      "0            False                              3   \n",
      "1            False                              1   \n",
      "2            False                              1   \n",
      "3            False                              1   \n",
      "4            False                              1   \n",
      "\n",
      "   calculated_host_listings_count_entire_homes  \\\n",
      "0                                            3   \n",
      "1                                            1   \n",
      "2                                            1   \n",
      "3                                            0   \n",
      "4                                            0   \n",
      "\n",
      "   calculated_host_listings_count_private_rooms  \\\n",
      "0                                             0   \n",
      "1                                             0   \n",
      "2                                             0   \n",
      "3                                             1   \n",
      "4                                             1   \n",
      "\n",
      "   calculated_host_listings_count_shared_rooms  reviews_per_month  \\\n",
      "0                                            0               0.33   \n",
      "1                                            0               4.86   \n",
      "2                                            0               0.02   \n",
      "3                                            0               3.68   \n",
      "4                                            0               0.87   \n",
      "\n",
      "  n_host_verifications  \n",
      "0                    9  \n",
      "1                    6  \n",
      "2                    3  \n",
      "3                    4  \n",
      "4                    7  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "(28022, 50)\n"
     ]
    }
   ],
   "source": [
    "# File names of the four data sets\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "airbnbDataSet_filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(airbnbDataSet_filename)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I'll be using the NYC Airbnb data set.\n",
    "2. The label will be the review_scores_rating\n",
    "3. The problem is a supervised learning regression problem.\n",
    "4. I am thinking of using unstructured text data(name, description, host_about, etc.).\n",
    "5. This is important because it can showcase how words lead to a high rating for an airbnb. This can allow hosts to get an understanding of how the words they use to describe themselves and the booking can affect their rating. This paired with feedback if this project were to be paired with another model. This can then show hosts how to improve the way they sell themselves to get better ratings which can increase bookings and bring more money to the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                                                5\n",
      "description                                       570\n",
      "neighborhood_overview                            9816\n",
      "host_name                                           0\n",
      "host_location                                      60\n",
      "host_about                                      10945\n",
      "host_response_rate                              11843\n",
      "host_acceptance_rate                            11113\n",
      "host_is_superhost                                   0\n",
      "host_listings_count                                 0\n",
      "host_total_listings_count                           0\n",
      "host_has_profile_pic                                0\n",
      "host_identity_verified                              0\n",
      "neighbourhood_group_cleansed                        0\n",
      "room_type                                           0\n",
      "accommodates                                        0\n",
      "bathrooms                                           0\n",
      "bedrooms                                         2918\n",
      "beds                                             1354\n",
      "amenities                                           0\n",
      "price                                               0\n",
      "minimum_nights                                      0\n",
      "maximum_nights                                      0\n",
      "minimum_minimum_nights                              0\n",
      "maximum_minimum_nights                              0\n",
      "minimum_maximum_nights                              0\n",
      "maximum_maximum_nights                              0\n",
      "minimum_nights_avg_ntm                              0\n",
      "maximum_nights_avg_ntm                              0\n",
      "has_availability                                    0\n",
      "availability_30                                     0\n",
      "availability_60                                     0\n",
      "availability_90                                     0\n",
      "availability_365                                    0\n",
      "number_of_reviews                                   0\n",
      "number_of_reviews_ltm                               0\n",
      "number_of_reviews_l30d                              0\n",
      "review_scores_rating                                0\n",
      "review_scores_cleanliness                           0\n",
      "review_scores_checkin                               0\n",
      "review_scores_communication                         0\n",
      "review_scores_location                              0\n",
      "review_scores_value                                 0\n",
      "instant_bookable                                    0\n",
      "calculated_host_listings_count                      0\n",
      "calculated_host_listings_count_entire_homes         0\n",
      "calculated_host_listings_count_private_rooms        0\n",
      "calculated_host_listings_count_shared_rooms         0\n",
      "reviews_per_month                                   0\n",
      "n_host_verifications                                0\n",
      "dtype: int64\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "missing = df.isnull().sum()\n",
    "print(missing)\n",
    "num_columns = df.shape[1]\n",
    "print(num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data? \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I will stick with the main text based features, ignoring anything with numerical or boolean values.\n",
    "2. Some of my features have a lot of null values but because these are needed, I'll fill them with empty strings. I can then clean each of the text features by doing things such as setting text to lowercase and removing any stopwords. Then I'll combine each of the features into a single one before vectorizing it and then splitting the data for training/testing.\n",
    "3. The model will be a feedforward neural network.\n",
    "4. I'll train the model with a data split, use RMSE as a loss function, and monitor MAE. For validation, I'll use a validation split of 0.2 and then evaluate the model's performance on the test set using MAE and RMSE while also plotting predicted vs actual values. For improvement afterwards, I'll probably tweak different hyperparameters until I find the most accurate ones for this plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 00:17:15.118372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-07-31 00:17:15.118402: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28022, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning up the data\n",
    "\n",
    "text_features = [\"name\", \"description\", \"neighborhood_overview\", \"host_about\"]\n",
    "\n",
    "for col in text_features:\n",
    "    df[col] = df[col].fillna(\"\")\n",
    "    \n",
    "df[\"all_text\"] = df[\"name\"] + \" \" + df[\"description\"] + \" \" + df[\"neighborhood_overview\"] + \" \" + df[\"host_about\"]\n",
    "\n",
    "df = df[[\"all_text\", \"review_scores_rating\"]]\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"all_text\"]\n",
    "y = df[\"review_scores_rating\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 00:17:16.359316: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-07-31 00:17:16.359347: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-07-31 00:17:16.359364: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (i-0f58520e60b1e4b08): /proc/driver/nvidia/version does not exist\n",
      "2025-07-31 00:17:16.359585: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "MAX_FEATURES = 50000\n",
    "\n",
    "vectorizer = TextVectorization(\n",
    "    max_tokens=MAX_FEATURES,\n",
    "    output_mode='tf-idf',\n",
    "    standardize='lower_and_strip_punctuation',\n",
    ")\n",
    "vectorizer.adapt(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_input (InputLayer)      [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               6400128   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,408,449\n",
      "Trainable params: 6,408,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_input = Input(shape=(1,), dtype=tf.string, name=\"text_input\")\n",
    "\n",
    "x = vectorizer(text_input)\n",
    "x= Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1)(x)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=text_input, outputs=x)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
    "model.summary()                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "561/561 [==============================] - 8s 14ms/step - loss: 2.8025 - mae: 1.3205 - val_loss: 1.9044 - val_mae: 1.2325\n",
      "Epoch 2/10\n",
      "561/561 [==============================] - 8s 14ms/step - loss: 1.2228 - mae: 0.8466 - val_loss: 1.0445 - val_mae: 0.9216\n",
      "Epoch 3/10\n",
      "561/561 [==============================] - 8s 14ms/step - loss: 0.7576 - mae: 0.6343 - val_loss: 0.4913 - val_mae: 0.5931\n",
      "Epoch 4/10\n",
      "561/561 [==============================] - 8s 14ms/step - loss: 0.7802 - mae: 0.5007 - val_loss: 0.2969 - val_mae: 0.3840\n",
      "Epoch 5/10\n",
      "561/561 [==============================] - 8s 14ms/step - loss: 0.4486 - mae: 0.4446 - val_loss: 0.2782 - val_mae: 0.3598\n",
      "Epoch 6/10\n",
      "167/561 [=======>......................] - ETA: 5s - loss: 0.3582 - mae: 0.4178"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5605, 358720]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m----> 3\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test, y_pred))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(mae)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:207\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    144\u001b[0m     {\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m ):\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    211\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    104\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5605, 358720]"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(mae)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot()\n",
    "plt.xlabel('Actual Rating')\n",
    "plt.ylabel('Predicted Rating')\n",
    "plt.title('Actual vs Predicted Review Rating')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test, bins=30, alpha=0.6, label='Actual Ratings')\n",
    "plt.hist(y_pred, bins=30, alpha=0.6, label='Predicted Ratings')\n",
    "plt.xlabel('Review Score Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Actual vs Predicted Ratings')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
